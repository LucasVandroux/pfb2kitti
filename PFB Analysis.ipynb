{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme.txt\n",
    "_Extract from the readme.txt file_\n",
    "\n",
    "### Structure\n",
    "The VIPER dataset is split into training, validation, and test set. \n",
    "Each subset is further divided into a number of video sequences. Each video\n",
    "sequence was recorded in 1 of 5 environmental conditions (day, sunset, rain, \n",
    "night, snow). The frame rate of each sequence is approximately 15 fps.\n",
    "\n",
    "### Input images (img)\n",
    "Each image was recorded in 1080p (1920x1080 pixels). Due to the large number of \n",
    "frames, we provide the images in lossy JPG and lossless PNG format. \n",
    "\n",
    "### 2D/3D Bounding boxes (bb)\n",
    "We provide bounding boxes in 2D (on the image plane) and in 3D \n",
    "(in camera coordinate frame) for a subset of the semantic classes. The \n",
    "annotations are stored as one CSV file per frame. Each row in one of the files\n",
    "corresponds to a single object instance. The format for the columns is\n",
    "classID, instanceID, 2D bounding box (4 values), 3D bounding box in model \n",
    "coordinate frame (6 values), matrix to transform 3D bounding box into camera \n",
    "coordinate frame (16 values).\n",
    "An example for visualizing the bounding boxes for one frame is given in \n",
    "'drawBoundingBox.m'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Weather Conditions\n",
    "weather.txt : https://drive.google.com/uc?id=1fJTx6-bfKYQs1CQD1yh7RsTIjhR3n0y0&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences per weather condition:\n",
      " '-> snow: 12\n",
      " '-> night: 21\n",
      " '-> sunset: 17\n",
      " '-> rain: 8\n",
      " '-> day: 19\n"
     ]
    }
   ],
   "source": [
    "# Import the Weather information from weather.txt\n",
    "path_weather_file = '/Users/lucas/Documents/Master Thesis/gta_dataset/train/weather.txt'\n",
    "\n",
    "# List of the different weather conditions available\n",
    "list_weather = ['day', 'sunset', 'night', 'rain', 'snow']\n",
    "\n",
    "# Initialized dict to store weather information per folder\n",
    "weather_dict = {w: [] for w in list_weather}\n",
    "\n",
    "# File Organization [id_set, weather]:\n",
    "with open(path_weather_file) as f:\n",
    "    for line in f:\n",
    "        # Parse line\n",
    "        line_parsed = line.strip().split(',')\n",
    "\n",
    "        # Fill the dictionary with the values\n",
    "        weather_dict[line_parsed[1]].append(line_parsed[0])\n",
    "\n",
    "# Print repartition of the weather conditions\n",
    "print('Number of sequences per weather condition:')\n",
    "for w, l in weather_dict.items():\n",
    "    print(' \\'-> ' + w + ': ' + str(len(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Labels\n",
    "train_bb.zip: https://drive.google.com/uc?id=1r9xZmfAT75geV2ieotND4U7OMbBkp2OQ&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From KITTI:\n",
    " ↳ At least one object per image (Car, Cyclist or Pedestrian in  \n",
    " Easy: Min. bounding box height: 40 Px, Max. occlusion level: Fully visible, Max. truncation: 15 %\n",
    " Moderate: Min. bounding box height: 25 Px, Max. occlusion level: Partly occluded, Max. truncation: 30 %\n",
    " Hard: Min. bounding box height: 25 Px, Max. occlusion level: Difficult to see, Max. truncation: 50 %\n",
    " \n",
    " Correspondance KITTI classes with GTA_Dataset:\n",
    " 'Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc' or 'DontCare'\n",
    " In KITII buses and motorcycles and trailer are considered as MISC (see 00098.png) --> try to avoid them in the selection of the images\n",
    " \n",
    " Check if train in GTA can be seen as tram in KITTI or discard.\n",
    " \n",
    " DontCare are ambiguous or too small labels\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import the useful bboxes\n",
    "# From KITTI :\n",
    "#  ↳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image and reposition the labels.\n",
    "# convert ../Images/000[-9][0-9].png -resize 1242x683^ -crop 1242x375+0+84 -set filename:f '%t_1242x375.%e' +adjoin '%[filename:f]'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
